{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying TabTranformers to OS fingerprinting task using nmap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6dc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "import absl.logging\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "from torchmetrics import AUROC\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "###############################\n",
    "\n",
    "logging.captureWarnings(True)\n",
    "warnings.filterwarnings('ignore')\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "seed = 2024\n",
    "np.random.seed(seed)\n",
    "\n",
    "df = pd.read_csv(\"../dataset/dataset_no_encoded_4397.csv\")\n",
    "\n",
    "df.pop('Class.vendor_0')\n",
    "df.pop('Class.OSgen_0')\n",
    "df.pop('Class.device_0')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "OutVar = list(df.columns)[0]\n",
    "\n",
    "df.drop_duplicates(keep=False, inplace=True)\n",
    "\n",
    "# df.replace(['BSD', 'iOS', 'macOS', 'Solaris', 'Android'], 'Other', inplace=True)\n",
    "df = df[~df.isin(['BSD', 'iOS', 'macOS', 'Solaris', 'Android']).any(axis=1)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "###############################\n",
    "\n",
    "LABEL = OutVar\n",
    "\n",
    "NUMERIC_FEATURES = df.select_dtypes(include=['int64']).columns.tolist()\n",
    "CATEGORICAL_FEATURES = df.select_dtypes(include=['object']).columns.tolist()\n",
    "CATEGORICAL_FEATURES.remove(LABEL)\n",
    "\n",
    "FEATURES = list(NUMERIC_FEATURES) + list(CATEGORICAL_FEATURES)\n",
    "\n",
    "train_data, test_data = train_test_split(df, stratify=df[LABEL], test_size=0.20, random_state=seed)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "numeric_pipe = Pipeline([\n",
    "    ('impute', imputer),\n",
    "    ('scale', scaler),\n",
    "])\n",
    "numeric_pipe.fit(train_data[NUMERIC_FEATURES])\n",
    "train_data[NUMERIC_FEATURES] = numeric_pipe.transform(train_data[NUMERIC_FEATURES])\n",
    "test_data[NUMERIC_FEATURES] = numeric_pipe.transform(test_data[NUMERIC_FEATURES])\n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "categorical_pipe = Pipeline([\n",
    "    ('ordinalencoder', ordinal_encoder),\n",
    "])\n",
    "categorical_pipe.fit(df[CATEGORICAL_FEATURES])\n",
    "train_data[CATEGORICAL_FEATURES] = categorical_pipe.transform(train_data[CATEGORICAL_FEATURES])\n",
    "test_data[CATEGORICAL_FEATURES] = categorical_pipe.transform(test_data[CATEGORICAL_FEATURES])\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_pipe = Pipeline([\n",
    "    ('labelencoder', ordinal_encoder),\n",
    "])\n",
    "label_pipe.fit(df[LABEL].values.reshape(-1, 1))\n",
    "train_data[LABEL] = label_pipe.transform(train_data[LABEL].values.reshape(-1, 1))\n",
    "test_data[LABEL] = label_pipe.transform(test_data[LABEL].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "train_tensor_X_cat = torch.tensor(train_data[CATEGORICAL_FEATURES].values).int()\n",
    "train_tensor_X_num = torch.tensor(train_data[NUMERIC_FEATURES].values).float()\n",
    "train_tensor_Y = torch.tensor(train_data[LABEL].values).view(-1, 1).float()\n",
    "\n",
    "test_tensor_X_cat = torch.tensor(test_data[CATEGORICAL_FEATURES].values).int()\n",
    "test_tensor_X_num = torch.tensor(test_data[NUMERIC_FEATURES].values).float()\n",
    "test_tensor_Y = torch.tensor(test_data[LABEL].values).view(-1, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f4781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "\n",
    "cont_mean_std = torch.randn(10, 2)\n",
    "\n",
    "model = TabTransformer(\n",
    "    categories = (10, 5, 6, 5, 8),      # tuple containing the number of unique values within each category\n",
    "    num_continuous = 10,                # number of continuous values\n",
    "    dim = 32,                           # dimension, paper set at 32\n",
    "    dim_out = 1,                        # binary prediction, but could be anything\n",
    "    depth = 6,                          # depth, paper recommended 6\n",
    "    heads = 8,                          # heads, paper recommends 8\n",
    "    attn_dropout = 0.1,                 # post-attention dropout\n",
    "    ff_dropout = 0.1,                   # feed forward dropout\n",
    "    mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n",
    "    mlp_act = nn.ReLU(),                # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n",
    "    continuous_mean_std = cont_mean_std # (optional) - normalize the continuous values before layer norm\n",
    ")\n",
    "\n",
    "x_categ = torch.randint(0, 5, (1, 5))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
    "x_cont = torch.randn(1, 10)               # assume continuous values are already normalized individually\n",
    "\n",
    "pred = model(x_categ, x_cont) # (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a25d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.47005534172058105\n",
      "Epoch 2: Loss = 0.16299572587013245\n",
      "Epoch 3: Loss = 0.0054003456607460976\n",
      "Epoch 4: Loss = 0.17402833700180054\n",
      "Epoch 5: Loss = 0.013747833669185638\n",
      "Epoch 6: Loss = 0.06410405039787292\n",
      "Epoch 7: Loss = 0.07166294753551483\n",
      "Epoch 8: Loss = 0.007313206326216459\n",
      "Epoch 9: Loss = 0.014909959398210049\n",
      "Epoch 10: Loss = 0.03474622592329979\n",
      "Updated Prediction: tensor([[0.4847]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "\n",
    "# Random categorical and numerical features\n",
    "x_categ = torch.randint(0, 5, (1, 5))\n",
    "x_cont = torch.randn(1, 10)\n",
    "\n",
    "# Random predictions\n",
    "target = torch.randn(1, 1)\n",
    "\n",
    "# Train the model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(x_categ, x_cont)\n",
    "    loss = criterion(pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item()}\")\n",
    "\n",
    "# Updated prediction after training\n",
    "updated_pred = model(x_categ, x_cont)\n",
    "print(\"Updated Prediction:\", updated_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
